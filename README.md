# AlanBot v5.7 - Local AI Assistant

AlanBot is a persistent, offline command-line interface (CLI) for AI interaction on Linux systems. It leverages local neural networks via the Ollama backend. Version 5.7 introduces a stable display engine and a dedicated third model for hybrid logic.

## System Requirements

* **Operating System:** Linux (Ubuntu, Debian, Arch, etc.)
* **Disk Space:** Approximately **15GB** (Required for 3 distinct model weights: Llama, Qwen, and Mistral).
* **Internet Connection:** Required during installation to download model binaries and dependencies.
* **Root/Sudo Privileges:** Required for installing system dependencies (Ollama, Python).

## Installation

The provided shell script automates the installation of the Ollama backend, Python virtual environments, and required AI models.

1.  **Set Execution Permissions:**
    ```bash
    chmod +x setup_alanbot.sh
    ```

2.  **Execute Installer:**
    ```bash
    ./setup_alanbot.sh
    ```
    *Select **Option 1** from the menu. The script will automatically detect missing dependencies (including Ollama) and install them.*

## Usage

### System Commands

After installation, the following commands are available in the terminal:

| Command | Function |
| :--- | :--- |
| `menu-alanbot` | **Primary Interface.** Launches the session manager to select operation modes (Chat, Code, Hybrid) or load persistent history files. |
| `alanbot` | **Quick Resume.** Immediately launches the last active session configuration without loading the menu. |
| `./setup_alanbot.sh` | **Maintenance.** Execute the installer script again to update models, repair the environment, or uninstall the software. |

### Session Commands

The following keywords trigger specific system actions during an active session:

| Keyword | Action |
| :--- | :--- |
| `copy` | Extracts the most recent code block generated by the assistant and copies it to the system clipboard. |
| `menu` | Saves the current session state and returns to the `menu-alanbot` selection screen. |
| `clear` | Clears the terminal display. |
| `exit` / `quit` | Saves the current session state and terminates the application. |

## Model Architecture

The system utilizes a tri-model approach based on the selected mode:

* **General Chat:** Uses **Llama 3.2**. Optimized for natural language, mathematics, and creative writing.
* **Pro Coder:** Uses **Qwen 2.5 Coder**. Optimized for syntax generation, debugging, and logic.
* **Hybrid Mode:** Uses **Mistral 7B**. A balanced model capable of handling both logic and conversation simultaneously, replacing the previous experimental implementation.

## Troubleshooting

* **Display Glitches:** Version 5.7 includes a patch for terminal cursor overlapping. If issues persist, ensure your terminal emulator supports standard ANSI escape codes.
* **Connection Errors:** Ensure the Ollama service is active.
    ```bash
    sudo systemctl start ollama
    ```
* **Permission Denied:** Ensure `chmod +x` was applied to the setup script and that the user has sudo privileges for the initial setup.
