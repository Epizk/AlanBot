# AlanBot v5.6 - Local AI Assistant

AlanBot is a persistent, offline command-line interface (CLI) for AI interaction on Linux systems. It leverages local neural networks via the Ollama backend, utilizing **Qwen 2.5 Coder** for programming tasks and **Llama 3.2** for general natural language processing.

## System Requirements

* **Operating System:** Linux (Ubuntu, Debian, Arch, etc.)
* **Disk Space:** Approximately 10GB (Required for model weights).
* **Internet Connection:** Required during installation to download model binaries and dependencies.
* **Root/Sudo Privileges:** Required for installing system dependencies (Ollama, Python).

## Installation

The provided shell script automates the installation of the Ollama backend, Python virtual environments, and required AI models.

1.  **Set Execution Permissions:**
    ```bash
    chmod +x setup_alanbot.sh
    ```

2.  **Execute Installer:**
    ```bash
    ./setup_alanbot.sh
    ```
    *Select **Option 1** from the menu to proceed. The script will automatically detect missing dependencies (including Ollama) and install them.*

## Usage

### System Commands

After installation, the following commands are available in the terminal:

| Command | Function |
| :--- | :--- |
| `menu-alanbot` | **Primary Interface.** Launches the session manager to select operation modes (Chat, Code, Hybrid) or load persistent history files. |
| `alanbot` | **Quick Resume.** Immediately launches the last active session configuration without loading the menu. |
| `./setup_alanbot.sh` | **Maintenance.** Execute the installer script again to update models, repair the environment, or uninstall the software. |

### Session Commands

The following keywords trigger specific system actions during an active session:

| Keyword | Action |
| :--- | :--- |
| `copy` | Extracts the most recent code block generated by the assistant and copies it to the system clipboard. |
| `menu` | Saves the current session state and returns to the `menu-alanbot` selection screen. |
| `clear` | Clears the terminal display. |
| `exit` / `quit` | Saves the current session state and terminates the application. |

## Model Architecture

The system utilizes a dual-model approach based on the selected mode:

* **General Chat:** Uses **Llama 3.2**. Optimized for natural language, mathematics, and creative writing.
* **Pro Coder:** Uses **Qwen 2.5 Coder**. Optimized for syntax generation, debugging, and logic.
* **Hybrid (Experimental):** Forces the Qwen 2.5 model to adopt a conversational system prompt. Note that this mode may exhibit unstable behavior regarding tone and strictness.

## Troubleshooting

* **Connection Errors:** Ensure the Ollama service is active.
    ```bash
    sudo systemctl start ollama
    ```
* **Permission Denied:** Ensure `chmod +x` was applied to the setup script and that the user has sudo privileges for the initial setup.
